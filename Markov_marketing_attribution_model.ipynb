{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBST0zgLDUE+zI7BwBXhZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myriamnavas/markov-marketing-attribution-model/blob/main/Markov_marketing_attribution_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Análisis de Atribución de Marketing con Cadenas de Markov**##\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i85JdYfMTIRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook explicaremos paso a paso cómo implementar un modelo de atribución de marketing basado en cadenas de Markov. Este enfoque nos permite analizar el mérito de las conversiones a los diferentes canales de marketing o diferentes campañas de una manera que tiene en cuenta todo el recorrido del cliente, en lugar de asignar todo el mérito al primer o último toque."
      ],
      "metadata": {
        "id": "hgGiKTS4ZsaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo es proporcionar una herramienta capaz de dar sentido al dilema de la atribución donde cada plataforma que usamos mide de manera diferente. Este modelo no resuelve al 100% esta situación (para eso están los MMM) ya que toma los datos de base del informe de rutas de atribución de Google Analytics 4 o de Google Ads pero ofrece una información muy valiosa para entender cómo fluyen las campañas con los diferentes canales existentes dentro del mix de estrategias de marketing.\n"
      ],
      "metadata": {
        "id": "TYGrNnJPZ76G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo de atribución que se propone está basado en el método de las cadenas de Markov con las siguientes particularidades:\n",
        "\n",
        "\n",
        "1.   **Considera el recorrido completo del usuario**: A diferencia de los modelos simples, evalúa todas las interacciones que llevaron a la conversión.\n",
        "2.   **Combina diferentes enfoques:** Esta propuesta integra tres modelos, el removal effect, el first touch y un método \"balanced\" que integra tanto el efecto de eliminación como el de primer contacto en una proporción 40%/60%. Esta proporción está pensada para darle mayor peso a los canales de entrada, tradicionalmente minusvalorados por GA4.\n",
        "3.  **Incluye un proceso de convergencia:** Al probar distintos números de iteraciones, comprobamos cuándo los resultados dejan de cambiar significativamente, logrando un buen equilibrio entre precisión y tiempo de espera.\n",
        "4. **Visualización clara:** El diagrama Sankey muestra de manera intuitiva cómo fluyen los usuarios entre los diferentes canales antes de convertir.\n",
        "\n",
        "Para implementar este modelo con tus propios datos, necesitarás un CSV con las columnas 'path' y 'conversions', donde:\n",
        "\n",
        "\n",
        "*   **'path'** contiene la secuencia de canales separados por el separador (por defecto ' > ')   \n",
        "*   **'conversions'** indica el número de conversiones para cada ruta\n",
        "\n",
        "Este enfoque puede ayudarte a entender el customer journey y a distribuir de manera más justa el presupuesto de marketing entre los diferentes canales, basándote en su contribución a las conversiones.\n",
        "\n",
        "En este mismo repositorio tienes un archivo csv para que puedas probar el modelo.\n",
        "\n",
        "**Nota:** el modelo se ha probado con hasta 16 canales diferentes tardando un total de aproximadamente 45 minutos en pasar el modelo completo. Con un menor número de canales no son necesarias tantas iteraciones. Se recomienda empezar con secuencias de iteraciones bajas e ir ampliando para ajustar la convergencia del modelo."
      ],
      "metadata": {
        "id": "M8KIw32tTVgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Configuración inicial y carga de librerías**  \n",
        "\n",
        "Primero, cargaremos todas las librerías necesarias y configuraremos algunos parámetros globales."
      ],
      "metadata": {
        "id": "RWv9RFXCf8zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importación de librerías\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n"
      ],
      "metadata": {
        "id": "Q7TMiGQLTRxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Configuración de parámetros**  \n",
        "Establecemos los parámetros que controlarán la ejecución del modelo."
      ],
      "metadata": {
        "id": "Jet5oVoJhHYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# CONFIGURACIÓN\n",
        "# -------------------------------\n",
        "\n",
        "# Fijar la semilla para reproducibilidad\n",
        "np.random.seed(42)\n",
        "\n",
        "# Iteraciones a probar\n",
        "ITERATIONS_TO_TEST = [100000, 150000, 175000, 200000, 225000]\n",
        "\n",
        "# Variables globales para almacenar los resultados de atribución\n",
        "removal_attribution_global = {}\n",
        "first_touch_attribution_global = {}\n",
        "\n",
        "# Umbral mínimo de atribución\n",
        "MIN_ATTRIBUTION = 0.001\n",
        "\n",
        "# Método de atribución\n",
        "ATTRIBUTION_METHOD = 'balanced'\n",
        "\n",
        "# Ruta del archivo CSV con rutas y conversiones\n",
        "ruta_csv = \"PON_AQUI_LA_RUTA_DE_TU_ARCHIVO.csv\"  # Ajusta esta ruta a la ubicación del archivo en tu sistema\n",
        "\n",
        "# Separador entre canales\n",
        "separator = ' > '"
      ],
      "metadata": {
        "id": "4RBFyGGETet5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Conexión con Drive**  \n",
        "Montamos la conexión con Drive para que puedas ejecutar el modelo desde el Colab."
      ],
      "metadata": {
        "id": "jLwmKLnZTgwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the connection with Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ijOQivj7Tr8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Carga y procesamiento de datos**  \n",
        "La siguiente función se encarga de cargar los datos desde un CSV y procesarlos para crear la matriz de transición que utilizará la cadena de Markov.\n"
      ],
      "metadata": {
        "id": "XLHuGXYUT705"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# FUNCIONES\n",
        "# -------------------------------\n",
        "\n",
        "def load_and_process_data(csv_path, separator):\n",
        "    \"\"\"Carga y procesa los datos de rutas de conversión.\n",
        "\n",
        "    Args:\n",
        "        csv_path: Ruta al archivo CSV con los datos\n",
        "        separator: Separador entre canales en las rutas\n",
        "\n",
        "    Returns:\n",
        "        transition_matrix: Matriz de transición para la cadena de Markov\n",
        "        channel_counts: Contador de apariciones de cada canal\n",
        "        transition_counts: Contador de transiciones entre canales\n",
        "    \"\"\"\n",
        "\n",
        "    data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Verificar columnas necesarias\n",
        "    if 'path' not in data.columns or 'conversions' not in data.columns:\n",
        "        raise ValueError(\"El CSV debe contener las columnas 'path' y 'conversions'\")\n",
        "\n",
        "    # Contar apariciones y transiciones\n",
        "    channel_counts = defaultdict(int)\n",
        "    transition_counts = defaultdict(int)\n",
        "\n",
        "    for _, row in data.iterrows():\n",
        "        steps = row['path'].split(separator)\n",
        "        steps = ['START'] + steps + ['CONVERSION']\n",
        "\n",
        "        # Contar apariciones\n",
        "        for step in steps:\n",
        "            if step not in ['START', 'CONVERSION']:\n",
        "                channel_counts[step] += row['conversions']\n",
        "\n",
        "        # Contar transiciones\n",
        "        for i in range(len(steps) - 1):\n",
        "            transition_counts[(steps[i], steps[i+1])] += row['conversions']\n",
        "\n",
        "    # Crear matriz de transición\n",
        "    states = list(set([k[0] for k in transition_counts] + [k[1] for k in transition_counts]))\n",
        "    transition_matrix = pd.DataFrame(0.0, index=states, columns=states)\n",
        "\n",
        "    # Llenar la matriz de transición con probabilidades\n",
        "    for (from_state, to_state), count in transition_counts.items():\n",
        "        total_from = sum([v for (f, t), v in transition_counts.items() if f == from_state])\n",
        "        if total_from > 0:\n",
        "            transition_matrix.loc[from_state, to_state] = count / total_from\n",
        "\n",
        "    return transition_matrix, channel_counts, transition_counts\n",
        "\n"
      ],
      "metadata": {
        "id": "NuBMjpvMTh9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Simulación de probabilidad de conversión**  \n",
        "Esta función simula caminos a través de la cadena de Markov para estimar la probabilidad de conversión."
      ],
      "metadata": {
        "id": "3g7F4rFZjBr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_conversion_prob(matrix, start_state, n_simulations):\n",
        "   \"\"\"\n",
        "    Simula la probabilidad de conversión usando la matriz de transición de Markov.\n",
        "\n",
        "    Args:\n",
        "        matrix: Matriz de transición\n",
        "        start_state: Estado inicial ('START')\n",
        "        n_simulations: Número de simulaciones a realizar\n",
        "\n",
        "    Returns:\n",
        "        conversion_prob: Probabilidad estimada de conversión\n",
        "        path_channels: Conjunto de canales visitados en las simulaciones\n",
        "    \"\"\"\n",
        "    conversions = 0\n",
        "    path_channels = set()\n",
        "\n",
        "    for _ in range(n_simulations):\n",
        "        state = start_state\n",
        "        steps = 0\n",
        "        MAX_STEPS = 100\n",
        "\n",
        "        while steps < MAX_STEPS:\n",
        "            probs = matrix.loc[state].values\n",
        "            total_prob = probs.sum()\n",
        "\n",
        "            if total_prob < 1e-10:\n",
        "                break\n",
        "\n",
        "            probs = probs / total_prob\n",
        "\n",
        "            try:\n",
        "                next_state = np.random.choice(matrix.columns, p=probs)\n",
        "            except ValueError:\n",
        "                break\n",
        "\n",
        "            if next_state != 'START' and next_state != 'CONVERSION':\n",
        "                path_channels.add(next_state)\n",
        "\n",
        "            if next_state == 'CONVERSION':\n",
        "                conversions += 1\n",
        "                break\n",
        "            elif next_state == state or next_state == 'NULL':\n",
        "                break\n",
        "            else:\n",
        "                state = next_state\n",
        "                steps += 1\n",
        "\n",
        "    # Calcular probabilidad como proporción de simulaciones que terminaron en conversión\n",
        "    return conversions / n_simulations, path_channels\n",
        "\n"
      ],
      "metadata": {
        "id": "6roOryoyjA0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Cálculo de atribución**  \n",
        "Esta función implementa el cálculo de atribución utilizando diferentes métodos."
      ],
      "metadata": {
        "id": "WjiZDQw9jgm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_attribution(transition_matrix, n_simulations, method='balanced', min_attribution=0.001):\n",
        "   \"\"\"\n",
        "    Calcula la atribución de cada canal según el método elegido.\n",
        "\n",
        "    Args:\n",
        "        transition_matrix: Matriz de transición de Markov\n",
        "        n_simulations: Número de simulaciones a realizar\n",
        "        method: Método de atribución ('balanced', 'removal_effect', o 'first_touch_bias')\n",
        "        min_attribution: Valor mínimo de atribución\n",
        "\n",
        "    Returns:\n",
        "        attribution: Diccionario con la atribución de cada canal\n",
        "        original_prob: Probabilidad de conversión original\n",
        "        execution_time: Tiempo de ejecución\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Simular probabilidad original con todos los canales\n",
        "    original_prob, channels_in_paths = simulate_conversion_prob(transition_matrix, 'START', n_simulations)\n",
        "\n",
        "    # Calcular efectos\n",
        "    removal_effect = {}\n",
        "    first_touch_effect = {}\n",
        "\n",
        "    # Para cada canal, calcular su efecto\n",
        "    for channel in set(transition_matrix.columns) - {'START', 'CONVERSION', 'NULL'}:\n",
        "        # 1. Método de removal effect\n",
        "        matrix_copy = transition_matrix.copy()\n",
        "        matrix_copy.loc[:, channel] = 0\n",
        "        matrix_copy.loc[channel, :] = 0\n",
        "\n",
        "        prob_without, _ = simulate_conversion_prob(matrix_copy, 'START', n_simulations)\n",
        "        removal_effect[channel] = max(original_prob - prob_without, 0)\n",
        "\n",
        "        # 2. Método de first-touch\n",
        "        first_touch_count = transition_counts.get(('START', channel), 0)\n",
        "        total_first_touches = sum([v for (f, t), v in transition_counts.items() if f == 'START'])\n",
        "\n",
        "        if total_first_touches > 0:\n",
        "            first_touch_effect[channel] = first_touch_count / total_first_touches\n",
        "        else:\n",
        "            first_touch_effect[channel] = 0\n",
        "\n",
        "    # Normalización\n",
        "    total_removal = sum(removal_effect.values())\n",
        "    if total_removal > 0:\n",
        "        removal_attribution = {k: v / total_removal for k, v in removal_effect.items()}\n",
        "    else:\n",
        "        removal_attribution = {k: 0 for k in removal_effect}\n",
        "\n",
        "    total_first_touch = sum(first_touch_effect.values())\n",
        "    if total_first_touch > 0:\n",
        "        first_touch_attribution = {k: v / total_first_touch for k, v in first_touch_effect.items()}\n",
        "    else:\n",
        "        first_touch_attribution = {k: 0 for k in first_touch_effect}\n",
        "\n",
        "    # Elegir método final\n",
        "    if method == 'removal_effect':\n",
        "        attribution = removal_attribution\n",
        "    elif method == 'first_touch_bias':\n",
        "        attribution = first_touch_attribution\n",
        "    elif method == 'balanced':\n",
        "        # Combinar ambos métodos (60% removal, 40% first-touch)\n",
        "        attribution = {}\n",
        "        for channel in set(removal_attribution.keys()) | set(first_touch_attribution.keys()):\n",
        "            removal_value = removal_attribution.get(channel, 0)\n",
        "            first_touch_value = first_touch_attribution.get(channel, 0)\n",
        "            attribution[channel] = 0.6 * removal_value + 0.4 * first_touch_value\n",
        "\n",
        "    # Aplicar umbral mínimo\n",
        "    for channel in attribution:\n",
        "        if attribution[channel] < min_attribution and channel_counts[channel] > 0:\n",
        "            attribution[channel] = min_attribution\n",
        "\n",
        "    # Renormalizar\n",
        "    total_attr = sum(attribution.values())\n",
        "    attribution = {k: v / total_attr for k, v in attribution.items()}\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    # Guardar los valores de atribución original para uso posterior\n",
        "    global removal_attribution_global, first_touch_attribution_global\n",
        "    removal_attribution_global = removal_attribution\n",
        "    first_touch_attribution_global = first_touch_attribution\n",
        "\n",
        "    return attribution, original_prob, execution_time\n",
        "\n"
      ],
      "metadata": {
        "id": "qdMmo-zxjg9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Ejecución del experimento principal**  \n",
        "Ahora configuramos y ejecutamos el experimento completo, probando diferentes números de iteraciones."
      ],
      "metadata": {
        "id": "kOtuOYCmkKzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# EXPERIMENTO PRINCIPAL\n",
        "# -------------------------------\n",
        "\n",
        "print(\"Cargando y procesando datos...\")\n",
        "transition_matrix, channel_counts, transition_counts = load_and_process_data(ruta_csv, separator)\n",
        "print(f\"Matriz de transición creada con {len(transition_matrix.columns)} estados\")\n",
        "\n",
        "# Almacenar resultados para cada número de iteraciones\n",
        "all_results = {}\n",
        "execution_times = []\n",
        "conversion_probs = []\n",
        "nonzero_channels = []\n",
        "\n",
        "# Comprobar consistencia con diferentes números de iteraciones\n",
        "for n_iter in ITERATIONS_TO_TEST:\n",
        "    print(f\"\\nProbando con {n_iter} iteraciones...\")\n",
        "    attribution, conv_prob, exec_time = calculate_attribution(\n",
        "        transition_matrix,\n",
        "        n_iter,\n",
        "        method=ATTRIBUTION_METHOD,\n",
        "        min_attribution=MIN_ATTRIBUTION\n",
        "    )\n",
        "\n",
        "    all_results[n_iter] = attribution\n",
        "    execution_times.append(exec_time)\n",
        "    conversion_probs.append(conv_prob)\n",
        "    nonzero_channels.append(len([ch for ch, val in attribution.items() if val > 0]))\n",
        "\n",
        "    print(f\"Tiempo de ejecución: {exec_time:.2f} segundos\")\n",
        "    print(f\"Probabilidad de conversión: {conv_prob:.6f}\")\n",
        "    print(f\"Canales con atribución > 0: {nonzero_channels[-1]} de {len(attribution)}\")\n",
        "\n",
        "# Calcular diferencias entre ejecuciones consecutivas\n",
        "differences = []\n",
        "for i in range(1, len(ITERATIONS_TO_TEST)):\n",
        "    prev_iter = ITERATIONS_TO_TEST[i-1]\n",
        "    curr_iter = ITERATIONS_TO_TEST[i]\n",
        "\n",
        "    # Seleccionar top 10 canales según la mayor iteración\n",
        "    top_channels = sorted(all_results[curr_iter].items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "    top_channel_names = [ch for ch, _ in top_channels]\n",
        "\n",
        "    # Calcular diferencia promedio para estos canales\n",
        "    diffs = []\n",
        "    for channel in top_channel_names:\n",
        "        prev_value = all_results[prev_iter].get(channel, 0)\n",
        "        curr_value = all_results[curr_iter].get(channel, 0)\n",
        "        if curr_value > 0:  # Evitar división por cero\n",
        "            pct_diff = abs(curr_value - prev_value) / curr_value * 100\n",
        "            diffs.append(pct_diff)\n",
        "\n",
        "    avg_diff = sum(diffs) / len(diffs) if diffs else 0\n",
        "    differences.append(avg_diff)\n",
        "\n",
        "    print(f\"\\nDiferencia promedio en top 10 canales entre {prev_iter} y {curr_iter} iteraciones: {avg_diff:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GhhRbJ5MkLGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Visualización con diagrama Sankey**  \n",
        "Creamos un diagrama Sankey para visualizar el flujo entre canales."
      ],
      "metadata": {
        "id": "L_7bDl0Ikm3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# VISUALIZACIÓN DE RESULTADOS\n",
        "# -------------------------------\n",
        "\n",
        "# ---------------------------------\n",
        "# VISUALIZACIÓN – DIAGRAMA SANKEY\n",
        "# ---------------------------------\n",
        "\n",
        "# Crear el diagrama Sankey\n",
        "labels = list(set([k[0] for k in transition_counts] + [k[1] for k in transition_counts]))\n",
        "label_indices = {label: i for i, label in enumerate(labels)}\n",
        "\n",
        "sources = [label_indices[k[0]] for k in transition_counts.keys()]\n",
        "targets = [label_indices[k[1]] for k in transition_counts.keys()]\n",
        "values = list(transition_counts.values())\n",
        "\n",
        "# Verificar que tenemos datos válidos\n",
        "if not sources or not targets or not values:\n",
        "    print(\"⚠️ No hay suficientes datos para generar el diagrama Sankey\")\n",
        "else:\n",
        "    try:\n",
        "        fig = go.Figure(data=[go.Sankey(\n",
        "            node=dict(\n",
        "                pad=30,\n",
        "                thickness=20,\n",
        "                line=dict(color=\"black\", width=0.5),\n",
        "                label=labels,\n",
        "            ),\n",
        "            link=dict(\n",
        "                source=sources,\n",
        "                target=targets,\n",
        "                value=values\n",
        "            ))])\n",
        "\n",
        "        fig.update_layout(\n",
        "            title_text=\"Flujo de usuarios entre canales (Sankey)\",\n",
        "            font_size=12,\n",
        "            height=1000,  # Altura explícita\n",
        "            width=1800   # Anchura explícita\n",
        "        )\n",
        "\n",
        "        # Guardar como HTML\n",
        "        fig.write_html(\"sankey_markov.html\")\n",
        "        print(\"✅ Archivo 'sankey_markov.html' guardado correctamente.\")\n",
        "\n",
        "        # En Jupyter, esto mostrará el gráfico directamente\n",
        "        fig.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error al crear el diagrama Sankey: {e}\")\n",
        "        print(\"   Verifica que los datos de transición son válidos.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "64Zrk4fMknCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Visualización de resultados comparativos**  \n",
        "Creamos gráficos para comparar los resultados con diferentes números de iteraciones."
      ],
      "metadata": {
        "id": "bRjvBDV4lJI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Gráfico de tiempos de ejecución\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(ITERATIONS_TO_TEST, execution_times, 'o-')\n",
        "plt.title('Tiempo de ejecución vs. Iteraciones')\n",
        "plt.xlabel('Número de iteraciones')\n",
        "plt.ylabel('Tiempo (segundos)')\n",
        "plt.grid(True)\n",
        "\n",
        "# 2. Gráfico de probabilidad de conversión\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(ITERATIONS_TO_TEST, conversion_probs, 'o-')\n",
        "plt.title('Probabilidad de conversión vs. Iteraciones')\n",
        "plt.xlabel('Número de iteraciones')\n",
        "plt.ylabel('Probabilidad')\n",
        "plt.grid(True)\n",
        "\n",
        "# 3. Gráfico de canales con atribución no nula\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(ITERATIONS_TO_TEST, nonzero_channels, 'o-')\n",
        "plt.title('Canales con atribución > 0 vs. Iteraciones')\n",
        "plt.xlabel('Número de iteraciones')\n",
        "plt.ylabel('Número de canales')\n",
        "plt.grid(True)\n",
        "\n",
        "# 4. Gráfico de diferencias porcentuales\n",
        "if differences:\n",
        "    plt.subplot(2, 2, 4)\n",
        "    iter_pairs = [f\"{ITERATIONS_TO_TEST[i-1]} → {ITERATIONS_TO_TEST[i]}\" for i in range(1, len(ITERATIONS_TO_TEST))]\n",
        "    plt.bar(iter_pairs, differences)\n",
        "    plt.title('Diferencia % en top 10 canales')\n",
        "    plt.ylabel('Diferencia promedio (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('comparacion_iteraciones.png')\n",
        "print(\"✅ Gráfico 'comparacion_iteraciones.png' guardado correctamente.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-oU0h6wclJT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10 Generación de tablas comparativas**  \n",
        "Creamos una tabla que muestra cómo cambian los resultados con diferentes números de iteraciones."
      ],
      "metadata": {
        "id": "kWdK9v4Xlol8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear tabla comparativa de los top 10 canales\n",
        "final_results = all_results[ITERATIONS_TO_TEST[-1]]\n",
        "top_channels = sorted(final_results.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "comparison_data = []\n",
        "headers = ['Canal'] + [f'{n_iter} iter.' for n_iter in ITERATIONS_TO_TEST] + ['Máx. diferencia %']\n",
        "\n",
        "for channel, _ in top_channels:\n",
        "    row = [channel]\n",
        "    values = [all_results[n_iter].get(channel, 0) for n_iter in ITERATIONS_TO_TEST]\n",
        "    row.extend([f\"{val:.6f}\" for val in values])\n",
        "\n",
        "    # Calcular diferencia máxima\n",
        "    if len(values) > 1 and values[-1] > 0:  # Comparar con el valor final como referencia\n",
        "        max_diff = max([abs(val - values[-1]) / values[-1] * 100 for val in values[:-1]] or [0])\n",
        "        row.append(f\"{max_diff:.2f}\")\n",
        "    else:\n",
        "        row.append(\"N/A\")\n",
        "\n",
        "    comparison_data.append(row)\n",
        "\n",
        "# Crear DataFrame y guardar como CSV\n",
        "comparison_df = pd.DataFrame(comparison_data, columns=headers)\n",
        "comparison_df.to_csv('comparacion_atribucion.csv', index=False)\n",
        "print(\"✅ Archivo 'comparacion_atribucion.csv' guardado correctamente.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BczEe2Kplov5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Exportación de resultados completos**  \n",
        "Exportamos los resultados completos para cada conjunto de iteraciones."
      ],
      "metadata": {
        "id": "GDVlDKsbl45l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar y guardar el archivo completo de atribución para cada número de iteraciones\n",
        "for n_iter in ITERATIONS_TO_TEST:\n",
        "    # Obtener resultados de esta iteración\n",
        "    attribution = all_results[n_iter]\n",
        "\n",
        "    # Crear DataFrame con todos los canales y sus métricas\n",
        "    full_results = []\n",
        "    for channel in attribution.keys():\n",
        "        # Obtener valores de los diferentes métodos de atribución para esta iteración\n",
        "        removal_value = removal_attribution_global.get(channel, 0)\n",
        "        first_touch_value = first_touch_attribution_global.get(channel, 0)\n",
        "\n",
        "        full_results.append({\n",
        "            'channel': channel,\n",
        "            'attribution': attribution.get(channel, 0),\n",
        "            'apariciones': channel_counts.get(channel, 0),\n",
        "            'removal_effect': removal_value,\n",
        "            'first_touch': first_touch_value\n",
        "        })\n",
        "\n",
        "    # Crear y guardar DataFrame\n",
        "    full_df = pd.DataFrame(full_results)\n",
        "    full_df = full_df.sort_values(by='attribution', ascending=False)\n",
        "    filename = f'atribucion_completa_{n_iter}_iter.csv'\n",
        "    full_df.to_csv(filename, index=False)\n",
        "    print(f\"✅ Archivo '{filename}' guardado correctamente.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ifAtNyn5l5DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Conclusiones del análisis**\n",
        "Finalmente, mostramos un resumen de las conclusiones del análisis."
      ],
      "metadata": {
        "id": "_nJvQrmxmEt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumen de conclusiones\n",
        "print(\"\\n=== CONCLUSIONES ===\")\n",
        "print(f\"Diferencia promedio entre {ITERATIONS_TO_TEST[0]} y {ITERATIONS_TO_TEST[-1]} iteraciones: {sum(differences)/len(differences):.2f}%\")\n",
        "\n",
        "if sum(differences)/len(differences) < 5:\n",
        "    print(f\"✅ {ITERATIONS_TO_TEST[0]} iteraciones parecen suficientes (diferencia < 5%)\")\n",
        "elif sum(differences)/len(differences) < 10:\n",
        "    print(f\"⚠️ {ITERATIONS_TO_TEST[0]} iteraciones muestran variación moderada (diferencia < 10%)\")\n",
        "else:\n",
        "    print(f\"❌ Se recomienda usar al menos {ITERATIONS_TO_TEST[-1]} iteraciones (diferencia > 10%)\")\n",
        "\n",
        "print(\"\\nLas métricas sugeridas para decidir el número óptimo de iteraciones son:\")\n",
        "print(\"1. Estabilidad en los valores de atribución de los principales canales\")\n",
        "print(\"2. Número de canales con atribución no nula\")\n",
        "print(\"3. Tiempo de computación aceptable\")\n",
        "\n",
        "print(\"\\n✅ Análisis completado. Revisa los archivos generados para tomar una decisión informada.\")"
      ],
      "metadata": {
        "id": "R7I3X7y_mE4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}